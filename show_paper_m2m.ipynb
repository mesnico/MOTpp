{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import yaml\n",
    "# %matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "from omegaconf import OmegaConf\n",
    "from IPython.display import HTML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_one(run, csv_folder):\n",
    "    with open(run / 'config.json', 'r') as f:\n",
    "        cfg = json.load(f)\n",
    "    \n",
    "    tpt = \"-tpt{}\".format(cfg['model']['text_encoder']['num_prompt_tokens']) if 'num_prompt_tokens' in cfg['model']['text_encoder'] else ''\n",
    "    text_model = cfg['model']['text_encoder']['_target_'].replace('src.model.', '')\n",
    "    text_model = f\"{text_model}{tpt}\"\n",
    "\n",
    "    motion_model = cfg['model']['motion_encoder']['_target_'].replace('src.model.', '')\n",
    "\n",
    "    no_bkb = '_nobkb' if 'bkb_feats' in cfg['model']['contrastive_loss'] and not cfg['model']['contrastive_loss']['bkb_feats'] else ''\n",
    "    contrastive_loss = f\"_{cfg['model']['contrastive_loss']['infonce_loss_fn']['_target_'].replace('src.model.', '')}\" if 'infonce_loss_fn' in cfg['model']['contrastive_loss'] and cfg['model']['contrastive_loss']['infonce_loss_fn'] is not None else ''\n",
    "    lambda_start_epoch = f\"_{cfg['model']['contrastive_loss']['lambda_start_epoch']}\" if 'lambda_start_epoch' in cfg['model']['contrastive_loss'] and cfg['model']['contrastive_loss']['lambda_start_epoch'] is not None else ''\n",
    "    lambda_end_epoch = f\"_{cfg['model']['contrastive_loss']['lambda_end_epoch']}\" if 'lambda_end_epoch' in cfg['model']['contrastive_loss'] and cfg['model']['contrastive_loss']['lambda_end_epoch'] is not None else ''\n",
    "    klloss = f\"_{cfg['model']['contrastive_loss']['cross_consistent_type']}\" if 'cross_consistent_type' in cfg['model']['contrastive_loss'] and cfg['model']['contrastive_loss']['cross_consistent_type'] is not None else ''\n",
    "    pseudolab = f\"_pseudolab{cfg['model']['contrastive_loss']['use_length_as_pseudo_motion_label']}\" if 'use_length_as_pseudo_motion_label' in cfg['model']['contrastive_loss'] and cfg['model']['contrastive_loss']['use_length_as_pseudo_motion_label'] is not None else ''\n",
    "    no_teacher_m2m = '_no-teacher-m2m' if 'text_teacher_affects_m2m' in cfg['model']['contrastive_loss'] and not cfg['model']['contrastive_loss']['text_teacher_affects_m2m'] else ''\n",
    "    loss = cfg['model']['contrastive_loss']['_target_'].replace('src.model.', '') + no_bkb + contrastive_loss + klloss + lambda_start_epoch + lambda_end_epoch + pseudolab + no_teacher_m2m\n",
    "    if 'threshold_selfsim' in cfg['model']['contrastive_loss'] and cfg['model']['contrastive_loss']['threshold_selfsim'] is None:\n",
    "        loss = loss.replace('_with_filtering', '')\n",
    "\n",
    "    dataset_test = csv_folder.split('_')[0]\n",
    "    dataset_train = cfg['data']['test']['path'].split('/')[-1]\n",
    "    dataset = dataset_train + '->' + dataset_test # dataset_test\n",
    "    \n",
    "    common_space_dim = cfg['common_space_dim']\n",
    "    data_rep = cfg['data_rep']\n",
    "\n",
    "    if 'ACTOR' in motion_model:\n",
    "        motion_debug = '-debug-joints' if 'debug_encode_decode_joints' in cfg['model']['motion_encoder'] and cfg['model']['motion_encoder']['debug_encode_decode_joints'] else ''\n",
    "        with_feet = '-withfeet' if 'with_feet' in cfg['model']['motion_encoder'] and cfg['model']['motion_encoder']['with_feet'] else ''\n",
    "        motion_model = motion_model + motion_debug + with_feet\n",
    "\n",
    "    if 'MoViT' in motion_model:\n",
    "        time_mask = 'use_time_padding_mask' in cfg['model']['motion_encoder'] and cfg['model']['motion_encoder']['use_time_padding_mask']\n",
    "        graph_based = 'use_skeleton_connection_mask' in cfg['model']['motion_encoder'] and cfg['model']['motion_encoder']['use_skeleton_connection_mask']\n",
    "        time_mask = '-timemask' if time_mask else ''\n",
    "        graph_based = '-graph' if graph_based else ''\n",
    "        attention_type = '-' + cfg['model']['motion_encoder']['attention_type']\n",
    "        uniform = '-uniform' if 'uniform_sample' in cfg['model']['motion_encoder'] and cfg['model']['motion_encoder']['uniform_sample'] else ''\n",
    "        num_frames = '-{num_frames}'.format(num_frames=cfg['model']['motion_encoder']['num_frames'])\n",
    "        ff_dim = '-ff{ff_dim}'.format(ff_dim=cfg['model']['motion_encoder']['ff_dims']) if 'ff_dims' in cfg['model']['motion_encoder'] else ''\n",
    "        num_layers = f\"-{cfg['model']['motion_encoder']['num_transformer_layers']}layers\" if 'num_transformer_layers' in cfg['model']['motion_encoder'] else ''\n",
    "        motion_model = motion_model + '-' + cfg['model']['motion_encoder']['body_repres'] + time_mask + graph_based + uniform + attention_type + num_frames + ff_dim + num_layers\n",
    "    \n",
    "    data = []\n",
    "    for yamlf in (run / csv_folder).rglob('*.yaml'):\n",
    "        with open(yamlf, 'r') as f:\n",
    "            m = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        fname = yamlf.stem\n",
    "        split = fname.rsplit('_', 1)\n",
    "        if len(split) == 2:\n",
    "            protocol_name, threshold = split\n",
    "            threshold = threshold.split('-')[1]\n",
    "            data.append({'protocol': protocol_name, 'len_thresh': threshold, **m})\n",
    "        elif len(split) == 1:\n",
    "            protocol_name = split[0]\n",
    "            data.append({'protocol': protocol_name, **m})\n",
    "\n",
    "    data = pd.DataFrame(data)\n",
    "    if data.empty:\n",
    "        print(f'Pred folder is empty: {csv_folder}')\n",
    "    \n",
    "    data['text_model'] = text_model\n",
    "    data['motion_model'] = motion_model\n",
    "    data['loss'] = loss\n",
    "    data['dataset'] = dataset\n",
    "    data['common_space_dim'] = common_space_dim\n",
    "    data['data_rep'] = data_rep\n",
    "    data['run'] = cfg['rep']\n",
    "    \n",
    "    return data\n",
    "\n",
    "def collect_all(root, csv_folder):\n",
    "    root = Path(root)\n",
    "    metrics = [collect_one(csvf.parents[0], csvf.name) for csvf in list(root.rglob(csv_folder))]\n",
    "    metrics = pd.concat(metrics, ignore_index=True)\n",
    "    return metrics\n",
    "\n",
    "default_fields_dict = {\n",
    "    'R1': lambda x: u\"{:.2f}\".format(x),\n",
    "    'R5': lambda x: u\"{:.2f}\".format(x),\n",
    "    'R10': lambda x: u\"{:.2f}\".format(x),\n",
    "    'meanr': lambda x: u\"{:.1f}\".format(x),\n",
    "    'medr': lambda x: int(x),\n",
    "    'spice': lambda x: u\"{:.3f}\".format(x),\n",
    "    'spacy': lambda x: u\"{:.3f}\".format(x),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metrics for each detected run\n",
    "\n",
    "def summarize_metrics(\n",
    "        metrics, \n",
    "        protocol=None, \n",
    "        dataset=None, \n",
    "        text_model=None, \n",
    "        motion_model=None, \n",
    "        loss=None, \n",
    "        common_space_dim=[256], \n",
    "        data_rep=['cont_6d_plus_rifke'], \n",
    "        len_thresh=None, \n",
    "        melt=True, \n",
    "        run=None,\n",
    "        decimals=2):\n",
    "\n",
    "    id_vars = ['dataset', 'protocol', 'text_model', 'motion_model', 'loss', 'common_space_dim', 'data_rep']\n",
    "    # if len_thresh column is present, add \"len_thresh\" to id_vars\n",
    "    if 'len_thresh' in metrics.columns:\n",
    "        id_vars.append('len_thresh')\n",
    "\n",
    "    if run is None:\n",
    "        metrics = metrics.groupby(id_vars).mean().reset_index()\n",
    "    else:\n",
    "        # take the first run (rows with run = 0)\n",
    "        metrics = metrics[metrics['run'] == run]\n",
    "    \n",
    "    metrics.drop(columns=\"run\", inplace=True)\n",
    "\n",
    "    # create an \"average\" protocol which is obtained by averaging every metric across all protocols, for every id_vars\n",
    "    id_vars_without_protocol = list(id_vars)\n",
    "    id_vars_without_protocol.remove('protocol')\n",
    "    metrics_avg = metrics.drop(columns='protocol').groupby(id_vars_without_protocol).mean().reset_index()\n",
    "    metrics_avg['protocol'] = 'average'\n",
    "    metrics = pd.concat([metrics, metrics_avg], ignore_index=True)\n",
    "\n",
    "    if protocol is not None:\n",
    "        metrics = metrics[metrics['protocol'].isin(protocol)]\n",
    "        if len(protocol) == 1:\n",
    "            metrics.drop(columns=\"protocol\", inplace=True)\n",
    "            id_vars.remove('protocol')\n",
    "    if common_space_dim is not None:\n",
    "        metrics = metrics[metrics['common_space_dim'].isin(common_space_dim)]\n",
    "        if len(common_space_dim) == 1:\n",
    "            metrics.drop(columns=\"common_space_dim\", inplace=True)\n",
    "            id_vars.remove('common_space_dim')\n",
    "    if data_rep is not None:\n",
    "        metrics = metrics[metrics['data_rep'].isin(data_rep)]\n",
    "        if len(data_rep) == 1:\n",
    "            metrics.drop(columns=\"data_rep\", inplace=True)\n",
    "            id_vars.remove('data_rep')\n",
    "    if text_model is not None:\n",
    "        metrics = metrics[metrics['text_model'].isin(text_model)]\n",
    "        if len(text_model) == 1:\n",
    "            metrics.drop(columns=\"text_model\", inplace=True)\n",
    "            id_vars.remove('text_model')\n",
    "    if motion_model is not None:\n",
    "        metrics = metrics[metrics['motion_model'].isin(motion_model)]\n",
    "        if len(motion_model) == 1:\n",
    "            metrics.drop(columns=\"motion_model\", inplace=True)\n",
    "            id_vars.remove('motion_model')\n",
    "    if loss is not None:\n",
    "        metrics = metrics[metrics['loss'].isin(loss)]\n",
    "        if len(loss) == 1:\n",
    "            metrics.drop(columns=\"loss\", inplace=True)\n",
    "            id_vars.remove('loss')\n",
    "    if len_thresh is not None:\n",
    "        metrics = metrics[metrics['len_thresh'].isin(len_thresh)]\n",
    "        if len(len_thresh) == 1:\n",
    "            metrics.drop(columns=\"len_thresh\", inplace=True)\n",
    "            id_vars.remove('len_thresh')\n",
    "    if dataset is not None:\n",
    "        metrics = metrics[(metrics['dataset'] == dataset)]\n",
    "        metrics.drop(columns=\"dataset\", inplace=True)\n",
    "        id_vars.remove('dataset')\n",
    "\n",
    "    if melt:\n",
    "        metrics = metrics.melt(id_vars=id_vars, var_name=\"metric\")\n",
    "        metrics = metrics.pivot(index=id_vars, columns=\"metric\", values=\"value\")\n",
    "\n",
    "    # round to 2 decimal places\n",
    "    metrics = metrics.round(decimals)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename content of the table\n",
    "def rename_fn(v):\n",
    "    mapping = {'motions.MoViT_v2-body-parts-timemask-uniform-fact_encoder-200-ff1024-2layers': 'MoViT++',\n",
    "               'motions.MoViT-body-parts-timemask-uniform-divided_space_time-200-3layers': 'MoViT',\n",
    "               'losses.InfoNCECrossConsistent_kldiv_0_1': 'CCL self',\n",
    "               'losses.InfoNCECrossConsistent_kldiv_80_140': 'CCL 80-140',\n",
    "               'losses.InfoNCECrossConsistent_kldiv_40_100': 'CCL 40-100',\n",
    "               'losses.InfoNCECrossConsistent_kldiv_140_200': 'CCL 140-200',\n",
    "               'losses.InfoNCECrossConsistent_kldiv_500_600': 'CCL supervised',\n",
    "               'losses.InfoNCECrossConsistent_kldiv_80_140_no-teacher-m2m': 'CCL 80-140 no-teacher-m2m',\n",
    "               'losses.InfoNCECrossConsistent_kldiv_40_100_no-teacher-m2m': 'CCL 40-100 no-teacher-m2m',\n",
    "               'losses.InfoNCE': 'InfoNCE',\n",
    "               'losses.InfoNCE_with_filtering': 'InfoNCE+F',\n",
    "               'ACTORStyleEncoder': 'TMR',\n",
    "               'texts.CLIP': 'CLIP',\n",
    "               }\n",
    "    if v in mapping:\n",
    "        return mapping[v]\n",
    "    return v\n",
    "\n",
    "def paper_formatting(metrics, remapping, order=None, protocols_order=['guo', 'normal', 'nsim', 'threshold_0.95', 'average']):\n",
    "    index_cols = ['protocol', 'dataset', 'text_model', 'motion_model', 'loss']\n",
    "    # metrics = metrics[metrics['loss'].isin(['losses.InfoNCECrossConsistent_kldiv_80_140', 'losses.InfoNCE_with_filtering', 'losses.InfoNCE'])]\n",
    "    # rename values in the table\n",
    "    metrics = metrics.applymap(rename_fn)\n",
    "    # create multi-index where protocol is repeated\n",
    "    metrics = metrics.set_index(index_cols)\n",
    "    # metrics['model'] = metrics['motion_model'] + ' ' + metrics['text_model'] + ' ' + metrics['loss']\n",
    "    # rename the first level of the columns: from \"t2m\" to \"Text-to-Motion\" and from \"m2t\" to \"Motion-to-Text\"\n",
    "    #metrics.columns = metrics.columns.set_levels(['Motion-to-Text', 'Text-to-Motion'], level=0)\n",
    "\n",
    "    # reorder columns and rows\n",
    "    #metrics = metrics.reindex(columns=['R01', 'R02', 'R03', 'R05', 'R10', 'MedR'], level=1)\n",
    "\n",
    "    # select only the rows that are in the selections\n",
    "    # idx = pd.IndexSlice\n",
    "    # selections = list(remapping.keys())\n",
    "    # metrics = metrics.loc[idx[:, [x[0] for x in selections], [x[1] for x in selections], [x[2] for x in selections], [x[3] for x in selections]], :]\n",
    "    # Step 2: Extract levels 1 to 3 and apply the mapping\n",
    "    mapped_part = metrics.index.to_frame(index=False).loc[:, ['dataset', 'text_model', 'motion_model', 'loss']].apply(tuple, axis=1).map(remapping)\n",
    "\n",
    "    # Step 3: Combine level 0 with the mapped part\n",
    "    new_index = pd.MultiIndex.from_arrays([metrics.index.get_level_values(0), mapped_part], names=['protocol', 'method'])\n",
    "\n",
    "    # Step 4: Set the new index to the DataFrame\n",
    "    metrics.index = new_index\n",
    "\n",
    "    # delete rows where method part of the index is NaN\n",
    "    c = metrics.index.names\n",
    "    metrics = metrics.reset_index().dropna().set_index(c)\n",
    "\n",
    "    # order the rows by protocol\n",
    "    metrics = metrics.reindex(protocols_order, level=0)\n",
    "\n",
    "    if order is not None:\n",
    "        metrics = metrics.reindex(order, level=1)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def render_to_latex(metrics, rename_func=default_fields_dict, **latex_kwargs):\n",
    "    m = metrics.copy()\n",
    "     # make bold the best values\n",
    "\n",
    "    # Custom function to highlight the maximum value in each group\n",
    "    def highlight_best(data):\n",
    "        attr = 'font-weight: bold'\n",
    "        result = pd.DataFrame('', index=data.index, columns=data.columns)\n",
    "        for col in data.columns:\n",
    "            if 'MedR' in col:\n",
    "                best_idx = data.groupby(level=0)[[col]].idxmin()\n",
    "            else:\n",
    "                best_idx = data.groupby(level=0)[[col]].idxmax()\n",
    "            for idx in best_idx.values:\n",
    "                result.loc[idx, col] = attr\n",
    "        return result\n",
    "\n",
    "    styled_df = m.style.apply(highlight_best, axis=None)\n",
    "    ltex = styled_df.format(precision=3).to_latex(\n",
    "        **latex_kwargs\n",
    "    )\n",
    "    return ltex"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motion to Motion retrieval - Results on KIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect all data on kit\n",
    "ROOT = \"runs\"\n",
    "\n",
    "metrics = collect_all(ROOT, '*latest_m2m-metrics')\n",
    "metrics = summarize_metrics(\n",
    "    metrics,\n",
    "    data_rep=['cont_6d_plus_rifke_vels'],\n",
    "    motion_model=[\n",
    "        'ACTORStyleEncoder',\n",
    "        'motions.MoViT_v2-body-parts-timemask-uniform-fact_encoder-200-ff1024-2layers'\n",
    "    ],\n",
    "    decimals=4,\n",
    "    melt=False\n",
    "    )\n",
    "\n",
    "selection = {\n",
    "    ('kitml->kitml', 'TMR', 'TMR', 'InfoNCE+F'): 'TMR',\n",
    "    ('kitml->kitml', 'CLIP', 'MoViT', 'InfoNCE'): 'MoT',\n",
    "    ('kitml->kitml', 'TMR', 'MoViT++', 'CCL 40-100'): 'MoT++',\n",
    "    ('kitml->kitml', 'TMR', 'MoViT++', 'CCL self'): 'MoT++ self',\n",
    "    ('kitml->kitml', 'TMR', 'MoViT++', 'CCL supervised'): 'MoT++ supervised',\n",
    "    ('kitml->kitml', 'TMR', 'MoViT++', 'CCL 80-140 no-teacher-m2m'): 'MoT++ 80-140 ntm',\n",
    "    ('kitml->kitml', 'TMR', 'MoViT++', 'CCL 40-100 no-teacher-m2m'): 'MoT++ 40-100 ntm',\n",
    "}\n",
    "\n",
    "# order = ['TMR (only HML3D)', 'TMR', 'MoT', 'MoT++ self', 'MoT++ 40-100', 'MoT++ 80-140', 'MoT++ 140-200', 'MoT++ supervised']\n",
    "order = ['TMR', 'MoT', 'MoT++', 'MoT++ self', 'MoT++ supervised', 'MoT++ 80-140 ntm', 'MoT++ 40-100 ntm']\n",
    "metrics = paper_formatting(metrics, selection, order)\n",
    "metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motion to Motion retrieval - Train HumanML3D, Test KitML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect all data on kit\n",
    "ROOT = \"runs\"\n",
    "\n",
    "metrics = collect_all(ROOT, '*latest_m2m-metrics')\n",
    "metrics = summarize_metrics(\n",
    "    metrics,\n",
    "    data_rep=['cont_6d_plus_rifke_vels'],\n",
    "    motion_model=[\n",
    "        'ACTORStyleEncoder',\n",
    "        'motions.MoViT_v2-body-parts-timemask-uniform-fact_encoder-200-ff1024-2layers'\n",
    "    ],\n",
    "    decimals=4,\n",
    "    melt=False\n",
    "    )\n",
    "\n",
    "selection = {\n",
    "    ('humanml3d->kitml', 'TMR', 'TMR', 'InfoNCE+F'): 'TMR',\n",
    "    ('humanml3d->kitml', 'CLIP', 'MoViT', 'InfoNCE'): 'MoT',\n",
    "    ('humanml3d->kitml', 'TMR', 'MoViT++', 'CCL 40-100'): 'MoT++',\n",
    "    ('humanml3d->kitml', 'TMR', 'MoViT++', 'CCL self'): 'MoT++ self',\n",
    "    ('humanml3d->kitml', 'TMR', 'MoViT++', 'CCL supervised'): 'MoT++ supervised',\n",
    "    ('humanml3d->kitml', 'TMR', 'MoViT++', 'CCL 80-140 no-teacher-m2m'): 'MoT++ 80-140 ntm',\n",
    "    ('humanml3d->kitml', 'TMR', 'MoViT++', 'CCL 40-100 no-teacher-m2m'): 'MoT++ 40-100 ntm',\n",
    "}\n",
    "\n",
    "# order = ['TMR (only HML3D)', 'TMR', 'MoT', 'MoT++ self', 'MoT++ 40-100', 'MoT++ 80-140', 'MoT++ 140-200', 'MoT++ supervised']\n",
    "order = ['TMR', 'MoT', 'MoT++', 'MoT++ self', 'MoT++ supervised', 'MoT++ 80-140 ntm', 'MoT++ 40-100 ntm']\n",
    "metrics = paper_formatting(metrics, selection, order)\n",
    "metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motion to Motion retrieval - Train HumanML3D+KitML, Test KitML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect all data on kit\n",
    "ROOT = \"runs\"\n",
    "\n",
    "metrics = collect_all(ROOT, '*latest_m2m-metrics')\n",
    "metrics = summarize_metrics(\n",
    "    metrics,\n",
    "    data_rep=['cont_6d_plus_rifke_vels'],\n",
    "    # motion_model=[\n",
    "    #     'ACTORStyleEncoder',\n",
    "    #     'motions.MoViT_v2-body-parts-timemask-uniform-fact_encoder-200-ff1024-2layers'\n",
    "    # ],\n",
    "    decimals=4,\n",
    "    melt=False,\n",
    "    )\n",
    "\n",
    "selection = {\n",
    "    ('humanml3d_plus_kitml->kitml', 'TMR', 'TMR', 'InfoNCE+F'): 'TMR',\n",
    "    ('humanml3d_plus_kitml->kitml', 'CLIP', 'MoViT', 'InfoNCE'): 'MoT',\n",
    "    ('humanml3d_plus_kitml->kitml', 'TMR', 'MoViT++', 'CCL 40-100'): 'MoT++',\n",
    "    ('humanml3d_plus_kitml->kitml', 'TMR', 'MoViT++', 'CCL self'): 'MoT++ self',\n",
    "    ('humanml3d_plus_kitml->kitml', 'TMR', 'MoViT++', 'CCL supervised'): 'MoT++ supervised',\n",
    "    ('humanml3d_plus_kitml->kitml', 'TMR', 'MoViT++', 'CCL 80-140 no-teacher-m2m'): 'MoT++ 80-140 ntm',\n",
    "    ('humanml3d_plus_kitml->kitml', 'TMR', 'MoViT++', 'CCL 40-100 no-teacher-m2m'): 'MoT++ 40-100 ntm',\n",
    "}\n",
    "\n",
    "# order = ['TMR (only HML3D)', 'TMR', 'MoT', 'MoT++ self', 'MoT++ 40-100', 'MoT++ 80-140', 'MoT++ 140-200', 'MoT++ supervised']\n",
    "order = ['TMR', 'MoT', 'MoT++', 'MoT++ self']\n",
    "metrics = paper_formatting(metrics, selection, order)\n",
    "\n",
    "# remove primary_label_idx/mAP and primary_label_idx/nDCG columns\n",
    "metrics = metrics.drop(columns=['primary_label_idx/mAP', 'primary_label_idx/nDCG'])\n",
    "\n",
    "# remove top_level_label_idx/ from the beginning of the column names\n",
    "metrics.columns = metrics.columns.str.replace('top_level_label_idx/', '')\n",
    "metrics\n",
    "latex = render_to_latex(\n",
    "    metrics, \n",
    "    caption=\"M2M results on KIT. Train: KIT+HumanML\",\n",
    "    clines=\"skip-last;data\",\n",
    "    hrules=True,\n",
    "    column_format=\"llccccccccccccc\",\n",
    "    convert_css=True\n",
    ")\n",
    "\n",
    "print(latex)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "t2m_tmr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "21b5b823d51478c24d92373558a8362ffd3b5f2fe6f23fa17907c25559e3d9ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
